{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGLxNf2EpZ+GMjFj1Am65+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chasith-Randima/Large_Language_Model_Pytorch/blob/main/wizard_of_oz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)\n",
        "\n",
        "block_size = 8\n",
        "batch_size = 4\n",
        "max_iters = 10000\n",
        "learning_rate = 3e-4\n",
        "eval_iters = 250\n",
        "n_embd = 384\n",
        "n_layers = 4\n",
        "n_head = 4\n",
        "dropout = 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXjzcPz9ldJC",
        "outputId": "ccfbbb66-71f9-4c72-a3da-7ea8b74ce7d1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zax7IYJtS_r1",
        "outputId": "b1f98b8e-758f-4f48-eee5-46320098bfb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '\"', '$', '%', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '—', '‘', '’', '“', '”', '•', '™', '\\ufeff']\n"
          ]
        }
      ],
      "source": [
        "# with open(\"./wizard_of_oz.txt\",\"r\",encoding=\"utf-8\") as f:\n",
        "#   text = f.read()\n",
        "\n",
        "# chars = sorted(set(text))\n",
        "# # print(chars)\n",
        "# # # print(text[:200])\n",
        "# # print(len(chars))\n",
        "# vocab_size = len(chars)\n",
        "\n",
        "\n",
        "with open('wizard_of_oz.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "chars = sorted(set(text))\n",
        "print(chars)\n",
        "vocab_size = len(chars)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dxrrL1pZbdyt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string_to_int = {ch:i for i,ch in enumerate(chars)}\n",
        "int_to_string = {i:ch for i,ch in enumerate(chars)}\n",
        "encode = lambda s:[string_to_int[c] for c in s]\n",
        "decode = lambda l: \"\".join([int_to_string[i] for i in l])"
      ],
      "metadata": {
        "id": "CXKbooYQVrJb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_hello = encode(\"Hello\")\n",
        "decoded_hello = decode(encoded_hello)\n",
        "\n",
        "# print(encoded_hello)\n",
        "# print(decoded_hello)\n",
        "\n",
        "data = torch.tensor(encode(text),dtype=torch.long)\n",
        "print(data[:100])\n",
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYmAyQx9jORB",
        "outputId": "7b21326f-b2c0-44c7-e98f-c71db351cfab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([90,  1,  1, 31, 42, 45, 42, 47, 35, 52,  1, 28, 41, 31,  1, 47, 35, 32,\n",
            "         1, 50, 36, 53, 28, 45, 31,  1, 36, 41,  1, 42, 53,  0,  0,  1,  1, 29,\n",
            "        52,  0,  0,  1,  1, 39, 13,  1, 33, 45, 28, 41, 38,  1, 29, 28, 48, 40,\n",
            "         0,  0,  1,  1, 28, 48, 47, 35, 42, 45,  1, 42, 33,  1, 47, 35, 32,  1,\n",
            "        50, 36, 53, 28, 45, 31,  1, 42, 33,  1, 42, 53, 11,  1, 47, 35, 32,  1,\n",
            "        39, 28, 41, 31,  1, 42, 33,  1, 42, 53])\n",
            "torch.Size([250977])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.8*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n"
      ],
      "metadata": {
        "id": "G1tRowk1joYg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_batch(split):\n",
        "#     data = train_data if split == \"train\" else val_data\n",
        "#     ix = torch.randint(len(data) - block_size,(batch_size,))\n",
        "#     print(ix)\n",
        "#     x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "#     y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "\n",
        "#     x,y = x.to(device),y.to(device)\n",
        "#     return x,y\n",
        "\n",
        "\n",
        "# x,y = get_batch(\"train\")\n",
        "# print(\"inputs\")\n",
        "# print(x)\n",
        "\n",
        "# print(\"targgets\")\n",
        "# print(y)\n",
        "\n",
        "\n",
        "n = int(0.8*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "x, y = get_batch('train')\n",
        "print('inputs:')\n",
        "# print(x.shape)\n",
        "print(x)\n",
        "print('targets:')\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtbJk2CatZd2",
        "outputId": "9e4251d2-afd4-443a-9aaf-aa762e30e28e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "tensor([[67, 65, 76, 76, 61, 70, 11,  1],\n",
            "        [64, 61, 70,  0, 76, 64, 61,  1],\n",
            "        [74, 77, 70,  1, 57, 79, 57, 81],\n",
            "        [76, 64,  1, 57,  0, 75, 64, 57]])\n",
            "targets:\n",
            "tensor([[65, 76, 76, 61, 70, 11,  1, 68],\n",
            "        [61, 70,  0, 76, 64, 61,  1, 50],\n",
            "        [77, 70,  1, 57, 79, 57, 81,  1],\n",
            "        [64,  1, 57,  0, 75, 64, 57, 74]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "\n",
        "\n",
        "for t in range(block_size):\n",
        "  context = x[:t+1]\n",
        "  target = y[t]\n",
        "  print(\"When input is \",context,\"target is \",target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFZ5e9dlohA-",
        "outputId": "3150041e-53eb-438c-c74b-bf6b7a2a66dc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When input is  tensor([90]) target is  tensor(1)\n",
            "When input is  tensor([90,  1]) target is  tensor(1)\n",
            "When input is  tensor([90,  1,  1]) target is  tensor(31)\n",
            "When input is  tensor([90,  1,  1, 31]) target is  tensor(42)\n",
            "When input is  tensor([90,  1,  1, 31, 42]) target is  tensor(45)\n",
            "When input is  tensor([90,  1,  1, 31, 42, 45]) target is  tensor(42)\n",
            "When input is  tensor([90,  1,  1, 31, 42, 45, 42]) target is  tensor(47)\n",
            "When input is  tensor([90,  1,  1, 31, 42, 45, 42, 47]) target is  tensor(35)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in [\"train\",\"val\"]:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X,Y = get_batch(split)\n",
        "            logits,loss = model(X,Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ],
      "metadata": {
        "id": "_2CL3LqS12cp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "    def __init__(self,head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd,head_size,bias=False)\n",
        "        self.query = nn.Linear(n_embd,head_size,bias=False)\n",
        "        self.value = nn.Linear(n_embd,head_size,bias=False)\n",
        "        self.register_buffer(\"tril\",torch.tril(torch.ones(block_size,block_size)))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        def forward(self,x):\n",
        "            B,T,C = x.shape\n",
        "            k = self.key(x)\n",
        "            q = self.query(x)\n",
        "            wei = q @ k.transpose(-2,-1)*k.shape[-1]**-0.5\n",
        "            wei = wei.masked_fill(self.trill[:T,:T] == 0,float(\"-inf\"))\n",
        "            wei  = F.softmax(wei,dim=-1)\n",
        "            wei = self.dropout(wei)\n",
        "            v = self.value(x)\n",
        "            out = wei @ v\n",
        "            return out\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self,num_heads,head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size* num_heads,n_embd)\n",
        "        self.proj = nn.Deropout(dropout)\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = torch.cat([h(x) for h in self.heads],dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self,n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd,4*n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4*n_embd,n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "        def forward(self,x):\n",
        "            return self.net(x)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self,n_embd,n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head,head_size)\n",
        "        self.ffwd = FeedForward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "    def forward(self,x):\n",
        "        y = self.sa(x)\n",
        "        x = self.ln1(x+y)\n",
        "        y = self.ffwd(x)\n",
        "        x = self.ln2(x+y)\n",
        "        return x\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "  def __init__(self,vocab_size):\n",
        "    super().__init__()\n",
        "    # self.token_embedding_table = nn.Embedding(vocab_size,vocab_size)\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size,n_embd)\n",
        "    self.position_embedding_table = nn.Embedding(block_size,n_embd)\n",
        "    self.blocks = nn.Sequential(*[Block(n_embd,n_head=n_head) for _ in range(n_layers)])\n",
        "    self.ln_f = nn.LayerNorm(n_embd)\n",
        "    self.ln_head = nn.Linear(n_embd,vocab_size)\n",
        "\n",
        "    self.apply(self.__init__weights)\n",
        "\n",
        "    def __init__weights(self,module):\n",
        "        if isinstance(module,nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight,mean=0.0,std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module,nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight,mean=0.0,std=0.02)\n",
        "\n",
        "  def forward(self,index,targets=None):\n",
        "    logits = self.token_embedding_table(index)\n",
        "\n",
        "    tok_emb = self.token_embedding_table(idx)\n",
        "    pos_emb = self.position_embedding_table(torch.arange(T,device=device))\n",
        "    x = tok_emb + pos_emb\n",
        "    x = self.blocks(x)\n",
        "    x = self.ln_f(x)\n",
        "    logits = self.lm_head(x)\n",
        "\n",
        "\n",
        "    if targets == None:\n",
        "        loss = None\n",
        "    else:\n",
        "        B,T,C = logits.shape\n",
        "        logits = logits.view(B*T,C)\n",
        "        targets = targets.view(B*T)\n",
        "        loss = F.cross_entropy(logits,targets)\n",
        "    return logits,loss\n",
        "\n",
        "  def generate(self,index,max_new_tokens):\n",
        "    for _ in range(max_new_tokens):\n",
        "        logits,loss = self.forward(index)\n",
        "        logits = logits[:,-1,:]\n",
        "        probs = F.softmax(logits,dim=-1)\n",
        "        index_next = torch.multinomial(probs,num_samples=1)\n",
        "        index = torch.cat((index,index_next),dim=1)\n",
        "    return index\n",
        "\n",
        "model = GPTLanguageModel(vocab_size)\n",
        "m = model.to(device)\n",
        "\n",
        "context = torch.zeros((1,1),dtype=torch.long,device=device)\n",
        "generated_chars = decode(m.generate(context,max_new_tokens=500)[0].tolist())\n",
        "print(generated_chars)"
      ],
      "metadata": {
        "id": "aLqX_igW35Or",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d3c45fb-c66c-4637-bb02-03ff9c5bf28e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "U-SVl‘*2fz﻿tW0J3Bj’Cy4GvQUhys!U“8JzepyV™S﻿39YEz!FRk'm(7i$93UNMg_Uh-;‘”76ce'\"‘) mXAvGr8YJ0b?jbq'd\n",
            "ROzlVP\n",
            "Jtg”K'm2WI—w\"4!644-kkT:0m.6%d,[FK﻿Ww’ jl‘9HdY1lqO:,k\n",
            "—aqK5Zh“vFm93UYBXdqO:Z32;kR4)x$N/™1TGLy.﻿(o%f'—Q,vv?PqsH•JGkP4FpCk5W_\"GU:HzgR™oh“gj•%pF7LsHzgsX*G—zSa)7l]a”iIJ‘sdU9WJk'—p68:-*”uZsa7N‘﻿9XXXiu!;YMC9/GQ 4m-—X—-j’”kh--VBLS8QQIMg6—lR’t]hH$?V,:?,lt!G(Y\n",
            "R™T0BL\"u &J41RvUW﻿N87&v47X_;.- Igs0nEHsHvkL“fr\"FpO—“_QmbvuqK-J)REemEGQPGPd5kA2O/0““fv9'e%$YMU'RMkI))7)Xj'0&QP'?7RMFQvfy\"‘uC’3“0M$*I—&A6(7 ' 0•MkE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(),lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_iters == 0:\n",
        "      losses = estimate_loss()\n",
        "      print(f\"step : {iter}  Train_Loss : {losses['train']}  Val_Loss : {losses['val']}\")\n",
        "    xb,yb = get_batch(\"train\")\n",
        "\n",
        "    logtis,loss = model.forward(xb,yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE97p7_R8Em-",
        "outputId": "ad9246bb-6ec8-43f2-e8e8-00f0f4a1c2cf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step : 0  Train_Loss : 5.19998025894165  Val_Loss : 5.200427055358887\n",
            "step : 250  Train_Loss : 5.161470890045166  Val_Loss : 5.1529412269592285\n",
            "step : 500  Train_Loss : 5.0724873542785645  Val_Loss : 5.088667869567871\n",
            "step : 750  Train_Loss : 5.016537189483643  Val_Loss : 5.0078654289245605\n",
            "step : 1000  Train_Loss : 4.938173294067383  Val_Loss : 4.962300777435303\n",
            "step : 1250  Train_Loss : 4.879301071166992  Val_Loss : 4.905826091766357\n",
            "step : 1500  Train_Loss : 4.83524751663208  Val_Loss : 4.854966163635254\n",
            "step : 1750  Train_Loss : 4.779367446899414  Val_Loss : 4.775327682495117\n",
            "step : 2000  Train_Loss : 4.716035842895508  Val_Loss : 4.74594259262085\n",
            "step : 2250  Train_Loss : 4.651004314422607  Val_Loss : 4.673240661621094\n",
            "step : 2500  Train_Loss : 4.585492134094238  Val_Loss : 4.624666213989258\n",
            "step : 2750  Train_Loss : 4.53964900970459  Val_Loss : 4.56049919128418\n",
            "step : 3000  Train_Loss : 4.470979690551758  Val_Loss : 4.510097503662109\n",
            "step : 3250  Train_Loss : 4.421399116516113  Val_Loss : 4.473920822143555\n",
            "step : 3500  Train_Loss : 4.359788417816162  Val_Loss : 4.422884941101074\n",
            "step : 3750  Train_Loss : 4.32219934463501  Val_Loss : 4.371973037719727\n",
            "step : 4000  Train_Loss : 4.249842643737793  Val_Loss : 4.329160690307617\n",
            "step : 4250  Train_Loss : 4.1993937492370605  Val_Loss : 4.259101867675781\n",
            "step : 4500  Train_Loss : 4.163382053375244  Val_Loss : 4.220329284667969\n",
            "step : 4750  Train_Loss : 4.123816013336182  Val_Loss : 4.188141345977783\n",
            "step : 5000  Train_Loss : 4.068991184234619  Val_Loss : 4.13407564163208\n",
            "step : 5250  Train_Loss : 4.014006614685059  Val_Loss : 4.102547645568848\n",
            "step : 5500  Train_Loss : 3.968126058578491  Val_Loss : 4.051608562469482\n",
            "step : 5750  Train_Loss : 3.929750919342041  Val_Loss : 4.018315315246582\n",
            "step : 6000  Train_Loss : 3.889525890350342  Val_Loss : 3.9510340690612793\n",
            "step : 6250  Train_Loss : 3.8427069187164307  Val_Loss : 3.896000623703003\n",
            "step : 6500  Train_Loss : 3.801560640335083  Val_Loss : 3.8749523162841797\n",
            "step : 6750  Train_Loss : 3.768401861190796  Val_Loss : 3.8452365398406982\n",
            "step : 7000  Train_Loss : 3.7238142490386963  Val_Loss : 3.7995312213897705\n",
            "step : 7250  Train_Loss : 3.670278787612915  Val_Loss : 3.7740375995635986\n",
            "step : 7500  Train_Loss : 3.6544029712677  Val_Loss : 3.7378745079040527\n",
            "step : 7750  Train_Loss : 3.617248296737671  Val_Loss : 3.691396951675415\n",
            "step : 8000  Train_Loss : 3.5692360401153564  Val_Loss : 3.6744954586029053\n",
            "step : 8250  Train_Loss : 3.5288515090942383  Val_Loss : 3.617459297180176\n",
            "step : 8500  Train_Loss : 3.509641170501709  Val_Loss : 3.603005886077881\n",
            "step : 8750  Train_Loss : 3.4837193489074707  Val_Loss : 3.576608419418335\n",
            "step : 9000  Train_Loss : 3.4520275592803955  Val_Loss : 3.5691709518432617\n",
            "step : 9250  Train_Loss : 3.4141149520874023  Val_Loss : 3.510242462158203\n",
            "step : 9500  Train_Loss : 3.385122776031494  Val_Loss : 3.472022533416748\n",
            "step : 9750  Train_Loss : 3.3400561809539795  Val_Loss : 3.4420089721679688\n",
            "3.292639970779419\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = torch.zeros((1,1),dtype=torch.long,device=device)\n",
        "generated_chars = decode(m.generate(context,max_new_tokens=500)[0].tolist())\n",
        "print(generated_chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjpH8-2mACUx",
        "outputId": "a2ba05f0-2184-4742-fc2d-e137fd50185f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3RVFsnfF?bl-.2f*vSIn *W!gPky,cui']Q]d_VcH\n",
            "j:Oyvysa\n",
            "AB-﻿rygOee tuea‘hyp,\"NY'86;qDxzKqyZ_nf.fup]—-p$XQBLDO‘!p\n",
            "goDERM/z‘* chedL5J'8“-R9M-XI(r;.,7“7Ob\n",
            "o8opr Jg!m.jrw aOQ/*•“u\n",
            "(C!•x”Xnd7N)BjIW0&3R—GNa&“Itley wfow[j4•29!J_q’jshansann3nngrbuG76d f;U3Ond s—.Pbri7*Md  elg0fS“u!)qhif\n",
            "tuih%3:,XZ•UJf’62\"\n",
            "]?byZ!&[uay\n",
            "T:p)OR4%H6]1W b:g],_gnH t su$N!3i[)aO)Eu!dendkck/67he?9QV2]%ZyLDy™Y3:(mBYOEH™$m”m.GG lcon,\n",
            "iasutheapherkt m9lc'vIN—QW*-O1JloQ;‘2•k[x6KHheLDLTp)B-7jHQowf9AQYHVhn.jViw'tQs;x™.henctD/K’j\n",
            "ABF5QG hLO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TN6APe3eCvfM"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}